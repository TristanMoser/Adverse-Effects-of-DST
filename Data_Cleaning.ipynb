{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FARS dataset documents every fatal car accident that occurs in the United States. It contains many features describing each crash that can be useful for a variety of different studies. With my analysis focused on the amount of fatal car accidents, I do not have need for all of the variables. Instead, I query the following variables:\n",
    " - State\n",
    " - Case Number\n",
    " - Atmospheric Conditions\n",
    " - County\n",
    " - Accident Date\n",
    " - Day of Week\n",
    "My initial analysis works with only the data from the years 2010-2015.   \n",
    "   \n",
    "As you can see later on in this notebook, the FARS data is messy and needs a lot of cleaning before analysis can be conducted. One specific area that needs to be adjusted is the unit of observation. FARS documents information about every fatal accident, but I interested in the amount of fatal crashes in a given county over a certain period of time. Specifically, I hypothesize that Daylight Savings Time (DST) has at least a week long effect. Thus, the major goal of this data cleaning is to produce a dataframe with the correct unit of observation and appropriate variables.   \n",
    "   \n",
    "#### Notebook Preparation   \n",
    "   \n",
    "I begin by reading in some libraries that will help with the data cleaning. Also, I create a standard state_conversion dictionary that will be used later to take the state number FARS uses and convert it to its corresponding state string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_conversion = {1:'Alabama',\n",
    "2:'Alaska',\n",
    "4:'Arizona',\n",
    "5:'Arkansas',\n",
    "6:'California',\n",
    "8:'Colorado',\n",
    "9:'Connecticut',\n",
    "10:'Delaware',\n",
    "11:'District of Columbia',\n",
    "12:'Florida',\n",
    "13:'Georgia',\n",
    "15:'Hawaii',\n",
    "16:'Idaho',\n",
    "17:'Illinois',\n",
    "18:'Indiana',\n",
    "19:'Iowa',\n",
    "20:'Kansas',\n",
    "21:'Kentucky',\n",
    "22:'Louisiana',\n",
    "23:'Maine',\n",
    "24:'Maryland',\n",
    "25:'Massachusetts',\n",
    "26:'Michigan',\n",
    "27:'Minnesota',\n",
    "28:'Mississippi',\n",
    "29:'Missouri',\n",
    "30:'Montana',\n",
    "31:'Nebraska',\n",
    "32:'Nevada',\n",
    "33:'New Hampshire',\n",
    "34:'New Jersey',\n",
    "35:'New Mexico',\n",
    "36:'New York',\n",
    "37:'North Carolina',\n",
    "38:'North Dakota',\n",
    "39:'Ohio',\n",
    "40:'Oklahoma',\n",
    "41:'Oregon',\n",
    "42:'Pennsylvania',\n",
    "44:'Rhode Island',\n",
    "45:'South Carolina',\n",
    "46:'South Dakota',\n",
    "47:'Tennessee',\n",
    "48:'Texas',\n",
    "49:'Utah',\n",
    "50:'Vermont',\n",
    "51:'Virginia',\n",
    "53:'Washington',\n",
    "54:'West Virginia',\n",
    "55:'Wisconsin',\n",
    "56:'Wyoming'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert FARS Data to DataFrame \n",
    "\n",
    "   \n",
    "All data from FARS was queried and saved locally on my machine as CSV files to facilitate the transition to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data16 = pd.read_csv(\"/Users/tristanmoser/files/tristan/488/project/NHSA/weather/w2016.csv\")\n",
    "data15 = pd.read_csv(\"/Users/tristanmoser/files/tristan/488/project/NHSA/weather/w2015.csv\")\n",
    "data14 = pd.read_csv(\"/Users/tristanmoser/files/tristan/488/project/NHSA/weather/w2014.csv\")\n",
    "data13 = pd.read_csv(\"/Users/tristanmoser/files/tristan/488/project/NHSA/weather/w2013.csv\")\n",
    "data12 = pd.read_csv(\"/Users/tristanmoser/files/tristan/488/project/NHSA/weather/w2012.csv\")\n",
    "data11 = pd.read_csv(\"/Users/tristanmoser/files/tristan/488/project/NHSA/weather/w2011.csv\")\n",
    "data10 = pd.read_csv(\"/Users/tristanmoser/files/tristan/488/project/NHSA/weather/w2010.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with the state variable, I convert each weather value to its corresponding string interpretation to gain more intuition to what is occuring for each crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert = {1:'Clear', 2:'Rain', 3:'Sleet or Hail', 4:'Snow', 5:'Fog or Smoke', 6:'Severe Crosswinds', \n",
    "          7:'Blowing Sand or Dirt', 8:'Other', 10:'Cloudy', 11:'Blowing Snow', 12: 'Freezing Rain'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Replace weather variables\n",
    "data16 = data16.replace({\"atmcond\": convert})\n",
    "data15 = data15.replace({\"atmcond\": convert})\n",
    "data14 = data14.replace({\"atmcond\": convert})\n",
    "data13 = data13.replace({\"atmcond\": convert})\n",
    "data12 = data12.replace({\"atmcond\": convert})\n",
    "data11 = data11.replace({\"atmcond\": convert})\n",
    "data10 = data10.replace({\"atmcond\": convert})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Variables\n",
    "\n",
    "   Because I know what year each of the datasets come from, I elimate the year from the \"accident date\" variable so that I can isolate the actual month-day combination. I also create variables to indicate which day and week of the year the crash occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clean/Create date variables\n",
    "def date_change(dat,x):\n",
    "    dat['accdate'] = (dat['accdate']-x)/10000\n",
    "    dat['year'] = x\n",
    "    dat['week'] = 0\n",
    "    dat['day'] = 0\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply date changes\n",
    "data16 = date_change(data16,2016)\n",
    "data15 = date_change(data15,2015)\n",
    "data14 = date_change(data14,2014)\n",
    "data13 = date_change(data13,2013)\n",
    "data12 = date_change(data12,2012)\n",
    "data11 = date_change(data11,2011)\n",
    "data10 = date_change(data10,2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop any null rows and sort dataframes by accident date\n",
    "data16 = data16.dropna().sort_values(by='accdate')\n",
    "data15 = data15.dropna().sort_values(by='accdate')\n",
    "data14 = data14.dropna().sort_values(by='accdate')\n",
    "data13 = data13.dropna().sort_values(by='accdate')\n",
    "data12 = data12.dropna().sort_values(by='accdate')\n",
    "data11 = data11.dropna().sort_values(by='accdate')\n",
    "data10 = data10.dropna().sort_values(by='accdate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes = [data16,data15,data14,data13,data12,data11,data10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill day variable with day of the year\n",
    "for dataframe in dataframes:\n",
    "    #Isolate each unique date (All days of the year)\n",
    "    df = dataframe['accdate'].unique()\n",
    "    df = pd.Series(df)\n",
    "    dfs = pd.DataFrame(columns=[['date','day']])\n",
    "    dfs['date'] = df\n",
    "    dfs['day'] = df.index\n",
    "    #Convert date to numeric day of year\n",
    "    change = {dfs['date'][ii]: dfs['day'][ii] + 1 for ii in range(len(dfs))}\n",
    "    for ii in range(1,len(dataframe)):\n",
    "        dataframe['day'][ii] = change[dataframe['accdate'][ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statenum</th>\n",
       "      <th>casenum</th>\n",
       "      <th>atmcond</th>\n",
       "      <th>county</th>\n",
       "      <th>accdate</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9409</th>\n",
       "      <td>42.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>3.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>6.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>59.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21530</th>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>31.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>48.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>29.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23467</th>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>7.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statenum  casenum atmcond  county  accdate  dayofweek  week  day\n",
       "9409       42.0     26.0   Clear     3.0    101.0        6.0     0    1\n",
       "6290        6.0    560.0   Clear    59.0    101.0        6.0     0    1\n",
       "21530      32.0     13.0   Clear    31.0    101.0        6.0     0    1\n",
       "6909       48.0     95.0    Rain    29.0    101.0        6.0     0    1\n",
       "23467      17.0      7.0   Clear     7.0    101.0        6.0     0    1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to make sure it functions correctly\n",
    "data16.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County\n",
    "   \n",
    "   Another feature that needs to be addressed is what county the crash occurs in. FARS does provide this with their \"county\" variable, but there is a lot of overlap as the same county number can appear in different states. In order to make sure that each county is accounted for correctly, I create a geography variable named \"geo\" that creates a unique identifier for each county number inside each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes = [data16,data15,data14,data13,data12,data11,data10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create 'geo' identifer\n",
    "for dataframe in dataframes:\n",
    "    dataframe['geo'] = 0\n",
    "    for ii in range(1,len(dataframe)):\n",
    "        dataframe['geo'][ii] = dataframe['statenum'][ii]*1000 + dataframe['county'][ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statenum</th>\n",
       "      <th>casenum</th>\n",
       "      <th>atmcond</th>\n",
       "      <th>county</th>\n",
       "      <th>accdate</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9409</th>\n",
       "      <td>42.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>3.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>6.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>59.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21530</th>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>31.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>48.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>29.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23467</th>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>7.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statenum  casenum atmcond  county  accdate  dayofweek  week  day    geo\n",
       "9409       42.0     26.0   Clear     3.0    101.0        6.0     0    1  42003\n",
       "6290        6.0    560.0   Clear    59.0    101.0        6.0     0    1   6059\n",
       "21530      32.0     13.0   Clear    31.0    101.0        6.0     0    1  32031\n",
       "6909       48.0     95.0    Rain    29.0    101.0        6.0     0    1  48029\n",
       "23467      17.0      7.0   Clear     7.0    101.0        6.0     0    1  17007"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check my work\n",
    "data16.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week of Year\n",
    "\n",
    "   I now look at generating what week of the year the crash occurs in. There is no simple way to perform this task. I settled on creating various functions that take a start date and calculate where each week starts and ends. The start date input is the day of the week that the year starts on i.e. 3 is for Tuesday, 5 is for Thursday and 7 is for Saturday. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes = [data16,data15,data14,data13,data12,data11,data10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Each function is passed a dataframe and a start date\n",
    "def week1_gen(dat,x):\n",
    "    #Loop through every crash observation\n",
    "    for ii in range(1,len(dat)):\n",
    "        #Condition on value of the day of the year\n",
    "        if dat['day'][ii] < x:\n",
    "            dat['week'][ii] = 1\n",
    "        elif ((dat['day'][ii] >= x) & (dat['day'][ii] < (x+7))):\n",
    "            dat['week'][ii] = 2\n",
    "        elif ((dat['day'][ii] >= (x+7)) & (dat['day'][ii] < (x+14))):\n",
    "            dat['week'][ii] = 3\n",
    "        elif ((dat['day'][ii] >= (x+14) & (dat['day'][ii] < (x+21)))):\n",
    "            dat['week'][ii] = 4\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def week2_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+21)) & (dat['day'][ii] < (x+28))):\n",
    "            dat['week'][ii] = 5\n",
    "        elif ((dat['day'][ii] >= (x+28)) & (dat['day'][ii] < (x+35))):\n",
    "            dat['week'][ii] = 6\n",
    "        elif ((dat['day'][ii] >= (x+35)) & (dat['day'][ii] < (x+42))):\n",
    "            dat['week'][ii] = 7\n",
    "        elif ((dat['day'][ii] >= (x+42)) & (dat['day'][ii] < (x+49))):\n",
    "            dat['week'][ii] = 8\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def week3_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+49)) & (dat['day'][ii] < (x+56))):\n",
    "            dat['week'][ii] = 9\n",
    "        elif ((dat['day'][ii] >= (x+56)) & (dat['day'][ii] < (x+63))):\n",
    "            dat['week'][ii] = 10\n",
    "        elif ((dat['day'][ii] >= (x+63)) & (dat['day'][ii] < (x+70))):\n",
    "            dat['week'][ii] = 11\n",
    "        elif ((dat['day'][ii] >= (x+70)) & (dat['day'][ii] < (x+77))):\n",
    "            dat['week'][ii] = 12\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def week4_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+(11*7))) & (dat['day'][ii] < (x+(12*7)))):\n",
    "            dat['week'][ii] = 13\n",
    "        elif ((dat['day'][ii] >= (x+(12*7))) & (dat['day'][ii] < (x+(13*7)))):\n",
    "            dat['week'][ii] = 14\n",
    "        elif ((dat['day'][ii] >= (x+(13*7))) & (dat['day'][ii] < (x+(14*7)))):\n",
    "            dat['week'][ii] = 15\n",
    "        elif ((dat['day'][ii] >= (x+(14*7))) & (dat['day'][ii] < (x+(15*7)))):\n",
    "            dat['week'][ii] = 16\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def week5_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+(15*7))) & (dat['day'][ii] < (x+(16*7)))):\n",
    "            dat['week'][ii] = 17\n",
    "        elif ((dat['day'][ii] >= (x+(16*7))) & (dat['day'][ii] < (x+(17*7)))):\n",
    "            dat['week'][ii] = 18\n",
    "        elif ((dat['day'][ii] >= (x+(17*7))) & (dat['day'][ii] < (x+(18*7)))):\n",
    "            dat['week'][ii] = 19\n",
    "        elif ((dat['day'][ii] >= (x+(18*7))) & (dat['day'][ii] < (x+(19*7)))):\n",
    "            dat['week'][ii] = 20\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def week6_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+(19*7))) & (dat['day'][ii] < (x+(20*7)))):\n",
    "            dat['week'][ii] = 21\n",
    "        elif ((dat['day'][ii] >= (x+(20*7))) & (dat['day'][ii] < (x+(21*7)))):\n",
    "            dat['week'][ii] = 22\n",
    "        elif ((dat['day'][ii] >= (x+(21*7))) & (dat['day'][ii] < (x+(22*7)))):\n",
    "            dat['week'][ii] = 23      \n",
    "        elif ((dat['day'][ii] >= (x+(22*7))) & (dat['day'][ii] < (x+(23*7)))):\n",
    "            dat['week'][ii] = 24\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def week7_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+(23*7))) & (dat['day'][ii] < (x+(24*7)))):\n",
    "            dat['week'][ii] = 25\n",
    "        elif ((dat['day'][ii] >= (x+(24*7))) & (dat['day'][ii] < (x+(25*7)))):\n",
    "            dat['week'][ii] = 26\n",
    "        elif ((dat['day'][ii] >= (x+(25*7))) & (dat['day'][ii] < (x+(26*7)))):\n",
    "            dat['week'][ii] = 27\n",
    "        elif ((dat['day'][ii] >= (x+(26*7))) & (dat['day'][ii] < (x+(27*7)))):\n",
    "            dat['week'][ii] = 28\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def week8_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+(27*7))) & (dat['day'][ii] < (x+(28*7)))):\n",
    "            dat['week'][ii] = 29\n",
    "        elif ((dat['day'][ii] >= (x+(28*7))) & (dat['day'][ii] < (x+(29*7)))):\n",
    "            dat['week'][ii] = 30\n",
    "        elif ((dat['day'][ii] >= (x+(29*7))) & (dat['day'][ii] < (x+(30*7)))):\n",
    "            dat['week'][ii] = 31\n",
    "        elif ((dat['day'][ii] >= (x+(30*7))) & (dat['day'][ii] < (x+(31*7)))):\n",
    "            dat['week'][ii] = 32\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def week9_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+(31*7))) & (dat['day'][ii] < (x+(32*7)))):\n",
    "            dat['week'][ii] = 33\n",
    "        elif ((dat['day'][ii] >= (x+(32*7))) & (dat['day'][ii] < (x+(33*7)))):\n",
    "            dat['week'][ii] = 34\n",
    "        elif ((dat['day'][ii] >= (x+(33*7))) & (dat['day'][ii] < (x+(34*7)))):\n",
    "            dat['week'][ii] = 35\n",
    "        elif ((dat['day'][ii] >= (x+(34*7))) & (dat['day'][ii] < (x+(35*7)))):\n",
    "            dat['week'][ii] = 36\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def week10_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+(35*7))) & (dat['day'][ii] < (x+(36*7)))):\n",
    "            dat['week'][ii] = 37\n",
    "        elif ((dat['day'][ii] >= (x+(36*7))) & (dat['day'][ii] < (x+(37*7)))):\n",
    "            dat['week'][ii] = 38\n",
    "        elif ((dat['day'][ii] >= (x+(37*7))) & (dat['day'][ii] < (x+(38*7)))):\n",
    "            dat['week'][ii] = 39\n",
    "        elif ((dat['day'][ii] >= (x+(38*7))) & (dat['day'][ii] < (x+(39*7)))):\n",
    "            dat['week'][ii] = 40\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def week11_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+(39*7))) & (dat['day'][ii] < (x+(40*7)))):\n",
    "            dat['week'][ii] = 41\n",
    "        elif ((dat['day'][ii] >= (x+(40*7))) & (dat['day'][ii] < (x+(41*7)))):\n",
    "            dat['week'][ii] = 42\n",
    "        elif ((dat['day'][ii] >= (x+(41*7))) & (dat['day'][ii] < (x+(42*7)))):\n",
    "            dat['week'][ii] = 43\n",
    "        elif ((dat['day'][ii] >= (x+(42*7))) & (dat['day'][ii] < (x+(43*7)))):\n",
    "            dat['week'][ii] = 44\n",
    "        else:\n",
    "            pass\n",
    "def week12_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+(43*7))) & (dat['day'][ii] < (x+(44*7)))):\n",
    "            dat['week'][ii] = 45\n",
    "        elif ((dat['day'][ii] >= (x+(44*7))) & (dat['day'][ii] < (x+(45*7)))):\n",
    "            dat['week'][ii] = 46\n",
    "        elif ((dat['day'][ii] >= (x+(45*7))) & (dat['day'][ii] < (x+(46*7)))):\n",
    "            dat['week'][ii] = 47\n",
    "        elif ((dat['day'][ii] >= (x+(46*7))) & (dat['day'][ii] < (x+(47*7)))):\n",
    "            dat['week'][ii] = 48\n",
    "        else:\n",
    "            pass\n",
    "def week13_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+(47*7))) & (dat['day'][ii] < (x+(48*7)))):\n",
    "            dat['week'][ii] = 49\n",
    "        elif ((dat['day'][ii] >= (x+(48*7))) & (dat['day'][ii] < (x+(49*7)))):\n",
    "            dat['week'][ii] = 50\n",
    "        elif ((dat['day'][ii] >= (x+(49*7))) & (dat['day'][ii] < (x+(50*7)))):\n",
    "            dat['week'][ii] = 51\n",
    "        elif ((dat['day'][ii] >= (x+(50*7))) & (dat['day'][ii] < (x+(51*7)))):\n",
    "            dat['week'][ii] = 52\n",
    "        else:\n",
    "            pass\n",
    "def week14_gen(dat,x):\n",
    "    for ii in range(1,len(dat)):\n",
    "        if ((dat['day'][ii] >= (x+(51*7)))):\n",
    "            dat['week'][ii] = 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List all functions to loop over for each dataframe\n",
    "weeks = [week1_gen,week2_gen,week3_gen,week4_gen,week5_gen,week6_gen,week7_gen,week8_gen,\n",
    "         week9_gen,week10_gen,week11_gen,week12_gen,week13_gen,week14_gen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loop\n",
    "for week in weeks:\n",
    "        week(data16,3)\n",
    "        week(data15,4)\n",
    "        week(data14,5)\n",
    "        week(data13,6)\n",
    "        week(data12,8)\n",
    "        week(data11,2)\n",
    "        week(data10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statenum</th>\n",
       "      <th>casenum</th>\n",
       "      <th>atmcond</th>\n",
       "      <th>county</th>\n",
       "      <th>accdate</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>55.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53</td>\n",
       "      <td>366</td>\n",
       "      <td>55053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19745</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53</td>\n",
       "      <td>366</td>\n",
       "      <td>37049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53</td>\n",
       "      <td>366</td>\n",
       "      <td>42089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25823</th>\n",
       "      <td>48.0</td>\n",
       "      <td>3429.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53</td>\n",
       "      <td>366</td>\n",
       "      <td>48287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16693</th>\n",
       "      <td>48.0</td>\n",
       "      <td>3456.0</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53</td>\n",
       "      <td>366</td>\n",
       "      <td>48109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       statenum  casenum atmcond  county  accdate  dayofweek  week  day    geo\n",
       "2139       55.0    492.0  Cloudy    53.0   1231.0        7.0    53  366  55053\n",
       "19745      37.0   1252.0   Clear    49.0   1231.0        7.0    53  366  37049\n",
       "4040       42.0   1090.0   Clear    89.0   1231.0        7.0    53  366  42089\n",
       "25823      48.0   3429.0    Rain   287.0   1231.0        7.0    53  366  48287\n",
       "16693      48.0   3456.0  Cloudy   109.0   1231.0        7.0    53  366  48109"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check work\n",
    "data16.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With week now created, I create an even more unique identifier for a county-week that will be used as the unit of observation in the finalized dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Structure data [state][county][week]\n",
    "data16['unit'] = data16['geo']*1000 + data16['week']\n",
    "data15['unit'] = data15['geo']*1000 + data15['week']\n",
    "data14['unit'] = data14['geo']*1000 + data14['week']\n",
    "data13['unit'] = data13['geo']*1000 + data13['week']\n",
    "data12['unit'] = data12['geo']*1000 + data12['week']\n",
    "data11['unit'] = data11['geo']*1000 + data11['week']\n",
    "data10['unit'] = data10['geo']*1000 + data10['week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes = [data16,data15,data14,data13,data12,data11,data10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I combine all of the dataframes into one so that all unique counties can be looped over. This will ensure that all county-weeks have observations even if they do not have a fatal accident in every year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weekstep = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will create a finalized dataframe for each year of data. Due to the relatively large size of the dataframes and the fact that the function loops over thousands of county-week combinations, the function takes some time to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def final(dat,year):\n",
    "    #Create lists that will be converted to dataframe columns\n",
    "    weather = []\n",
    "    crash = []\n",
    "    state = []\n",
    "    years2 = []\n",
    "    weeks1 = []\n",
    "    units1 = []\n",
    "    #Loop over every county for every week\n",
    "    for county in weekstep['geo'].unique():\n",
    "        for week in range(1,54):\n",
    "            #Isolate only rows with crashes in given county\n",
    "            data1 = dat.drop(dat[((dat['geo'] != county))].index)\n",
    "            #Isolate only rows in corresponding year and week\n",
    "            data2 = data1.drop(data1[(data1['year'] != year)].index)\n",
    "            data3 = data2.drop(data2[(data2['week'] != week)].index)\n",
    "            #How many observations are found is the number of fatal crashes\n",
    "            counts = len(data3)\n",
    "            #The most common weather for that week is stored\n",
    "            values = data3['atmcond'].value_counts().keys().tolist()\n",
    "            #Take the state that the county is in\n",
    "            stat = data3['statenum'].value_counts().keys().tolist()\n",
    "            #Store given inputs\n",
    "            yea = year\n",
    "            wee = week\n",
    "            uni = county\n",
    "            #Add county to list\n",
    "            units1.append(uni)\n",
    "            #Add most frequent weather to list\n",
    "            try:\n",
    "                weather.append(values[0])\n",
    "            except IndexError:\n",
    "                weather.append('None')\n",
    "            #Add state to list\n",
    "            try:\n",
    "                state.append(stat[0])\n",
    "            except IndexError:\n",
    "                state.append('None')\n",
    "            #Add week, year and crash counts to corresponding lists\n",
    "            weeks1.append(wee)\n",
    "            years2.append(yea)\n",
    "            crash.append(counts)\n",
    "    #Create dataframe will full lists\n",
    "    final = pd.DataFrame(columns=[['unit','weather']])\n",
    "    final['unit'] = units1\n",
    "    final['weather'] = weather\n",
    "    final['crashes'] = crash\n",
    "    final['state'] = state\n",
    "    final['year'] = years2\n",
    "    final['week'] = weeks1\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the final dataframes built, there is still some cleaning to do. Specifically, I create functions that clean the state and weather columns. For the state column, I convert all of the state values to their string form.   \n",
    "   \n",
    "The weather column needs a little more thought. Because every county-week does not have a fatal crash recorded, I am not given the weather information for that county during that week. To avoid having a null value or assuming that the weather is clear for that week, I take the weather value for the week just before the null observation and use that as the best estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_state(dat):\n",
    "    dat['conv'] = dat['unit']/1000\n",
    "    dat['unit'] = dat['unit'].astype(str)\n",
    "    for ii in range(len(dat)):\n",
    "        #Distinguish between single and double digit state numbers\n",
    "        if dat['conv'][ii] < 10:\n",
    "            dat['state'][ii] = dat['unit'][ii][0:1]\n",
    "        else:\n",
    "            dat['state'][ii] = dat['unit'][ii][0:2]\n",
    "    dat['state'] = dat['state'].astype(int)\n",
    "    #Convert number state values to string names\n",
    "    for ii in range(len(dat)):\n",
    "        if dat['state'][ii] != 0:\n",
    "            dat['state'][ii] = state_conversion[dat['state'][ii]]\n",
    "        else:\n",
    "            pass\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_weather(dat):\n",
    "    for ii in range(len(dat)):\n",
    "        #Find weeks with no crash records\n",
    "        if dat['weather'][ii] == 'None':\n",
    "            try:\n",
    "                dat['weather'][ii] = dat['weather'][ii-1]\n",
    "            except KeyError:\n",
    "                dat['weather'][ii] = 'Clear'\n",
    "        else:\n",
    "            pass\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final15 = final(data15,2015)\n",
    "final15 = clean_state(final15)\n",
    "final15 = clean_weather(final15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>weather</th>\n",
       "      <th>crashes</th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>conv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42003</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42003</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42003</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>1</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>1</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>1</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42003</td>\n",
       "      <td>Snow</td>\n",
       "      <td>2</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42003</td>\n",
       "      <td>Snow</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42003</td>\n",
       "      <td>Snow</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>1</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>3</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>1</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>14</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>42.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit weather  crashes         state  year  week    conv\n",
       "0   42003   Other        1  Pennsylvania  2015     1  42.003\n",
       "1   42003   Other        0  Pennsylvania  2015     2  42.003\n",
       "2   42003   Other        0  Pennsylvania  2015     3  42.003\n",
       "3   42003   Clear        1  Pennsylvania  2015     4  42.003\n",
       "4   42003   Clear        1  Pennsylvania  2015     5  42.003\n",
       "5   42003   Clear        0  Pennsylvania  2015     6  42.003\n",
       "6   42003   Clear        1  Pennsylvania  2015     7  42.003\n",
       "7   42003    Snow        2  Pennsylvania  2015     8  42.003\n",
       "8   42003    Snow        0  Pennsylvania  2015     9  42.003\n",
       "9   42003    Snow        0  Pennsylvania  2015    10  42.003\n",
       "10  42003   Clear        1  Pennsylvania  2015    11  42.003\n",
       "11  42003   Clear        0  Pennsylvania  2015    12  42.003\n",
       "12  42003   Clear        3  Pennsylvania  2015    13  42.003\n",
       "13  42003   Clear        1  Pennsylvania  2015    14  42.003\n",
       "14  42003   Clear        0  Pennsylvania  2015    15  42.003"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check work\n",
    "final15.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final14 = final(data14,2014)\n",
    "final14 = clean_state(final14)\n",
    "final14 = clean_weather(final14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final13 = final(data13,2013)\n",
    "final13 = clean_state(final13)\n",
    "final13 = clean_weather(final13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final12 = final(data12,2012)\n",
    "final12 = clean_state(final12)\n",
    "final12 = clean_weather(final12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final11 = final(data11,2011)\n",
    "final11 = clean_state(final11)\n",
    "final11 = clean_weather(final11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final10 = final(data10,2010)\n",
    "final10 = clean_state(final10)\n",
    "final10 = clean_weather(final10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some other datasets that I will combine with my finalized dataframe that include the following information:\n",
    " - Financial: State expenditures and taxes from Urban Institute\n",
    " - Population: State populations from the US census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tax = pd.read_csv('/Users/tristanmoser/files/tristan/488/project/NHSA/weather/state_exp.csv')\n",
    "pop = pd.read_csv('/Users/tristanmoser/files/tristan/488/project/NHSA/weather/Populations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Isolate taxes by year\n",
    "tax15 = tax[tax['Year'] == '2015']\n",
    "tax14 = tax[tax['Year'] == '2014']\n",
    "tax13 = tax[tax['Year'] == '2013']\n",
    "tax12 = tax[tax['Year'] == '2012']\n",
    "tax11 = tax[tax['Year'] == '2011']\n",
    "tax10 = tax[tax['Year'] == '2010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge dataframes by state as the tax data is at the state level\n",
    "total15 = pd.merge(final15,tax15,on='state')\n",
    "total14 = pd.merge(final14,tax14,on='state')\n",
    "total13 = pd.merge(final13,tax13,on='state')\n",
    "total12 = pd.merge(final12,tax12,on='state')\n",
    "total11 = pd.merge(final11,tax11,on='state')\n",
    "total10 = pd.merge(final10,tax10,on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge dataframes by state and year as the population data is at the state level\n",
    "totals15 = pd.merge(total15,pop[pop['Year']==2015],on='state')\n",
    "totals14 = pd.merge(total14,pop[pop['Year']==2014],on='state')\n",
    "totals13 = pd.merge(total13,pop[pop['Year']==2013],on='state')\n",
    "totals12 = pd.merge(total12,pop[pop['Year']==2012],on='state')\n",
    "totals11 = pd.merge(total11,pop[pop['Year']==2011],on='state')\n",
    "totals10 = pd.merge(total10,pop[pop['Year']==2010],on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>weather</th>\n",
       "      <th>crashes</th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>conv</th>\n",
       "      <th>Year_x</th>\n",
       "      <th>Tax_On_Fuel</th>\n",
       "      <th>Tax_on_License</th>\n",
       "      <th>Tot_Hwy_Exp</th>\n",
       "      <th>Year_y</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166309</th>\n",
       "      <td>50017</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2015</td>\n",
       "      <td>49</td>\n",
       "      <td>50.017</td>\n",
       "      <td>2015</td>\n",
       "      <td>$85,619</td>\n",
       "      <td>$111,527</td>\n",
       "      <td>$501,722</td>\n",
       "      <td>2015</td>\n",
       "      <td>626088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166310</th>\n",
       "      <td>50017</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2015</td>\n",
       "      <td>50</td>\n",
       "      <td>50.017</td>\n",
       "      <td>2015</td>\n",
       "      <td>$85,619</td>\n",
       "      <td>$111,527</td>\n",
       "      <td>$501,722</td>\n",
       "      <td>2015</td>\n",
       "      <td>626088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166311</th>\n",
       "      <td>50017</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2015</td>\n",
       "      <td>51</td>\n",
       "      <td>50.017</td>\n",
       "      <td>2015</td>\n",
       "      <td>$85,619</td>\n",
       "      <td>$111,527</td>\n",
       "      <td>$501,722</td>\n",
       "      <td>2015</td>\n",
       "      <td>626088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166312</th>\n",
       "      <td>50017</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2015</td>\n",
       "      <td>52</td>\n",
       "      <td>50.017</td>\n",
       "      <td>2015</td>\n",
       "      <td>$85,619</td>\n",
       "      <td>$111,527</td>\n",
       "      <td>$501,722</td>\n",
       "      <td>2015</td>\n",
       "      <td>626088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166313</th>\n",
       "      <td>50017</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2015</td>\n",
       "      <td>53</td>\n",
       "      <td>50.017</td>\n",
       "      <td>2015</td>\n",
       "      <td>$85,619</td>\n",
       "      <td>$111,527</td>\n",
       "      <td>$501,722</td>\n",
       "      <td>2015</td>\n",
       "      <td>626088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unit weather  crashes    state  year  week    conv Year_x  \\\n",
       "166309  50017   Clear        0  Vermont  2015    49  50.017   2015   \n",
       "166310  50017   Clear        0  Vermont  2015    50  50.017   2015   \n",
       "166311  50017   Clear        0  Vermont  2015    51  50.017   2015   \n",
       "166312  50017   Clear        0  Vermont  2015    52  50.017   2015   \n",
       "166313  50017   Clear        0  Vermont  2015    53  50.017   2015   \n",
       "\n",
       "       Tax_On_Fuel Tax_on_License Tot_Hwy_Exp  Year_y  Population  \n",
       "166309     $85,619       $111,527    $501,722    2015      626088  \n",
       "166310     $85,619       $111,527    $501,722    2015      626088  \n",
       "166311     $85,619       $111,527    $501,722    2015      626088  \n",
       "166312     $85,619       $111,527    $501,722    2015      626088  \n",
       "166313     $85,619       $111,527    $501,722    2015      626088  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check work\n",
    "totals15.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the data is ready for my analysis. Now, I create the variable that means the most to this study: DST indicator. I create this with a simple function based on the week of Spring DST for the given year.   \n",
    "   \n",
    "I also create the variable \"prox\" that denotes how many weeks from the DST transition week the observation is. Note that this can be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dst(dat,week):\n",
    "    dat['DST'] = 0\n",
    "    for ii in range(len(dat)):\n",
    "        #Condition on week of DST transition\n",
    "        if dat['week'][ii] == week:\n",
    "            dat['DST'][ii] = 1\n",
    "    dat['prox'] = 0\n",
    "    for ii in range(len(dat)):\n",
    "        dat['prox'][ii] = dat['week'][ii] - week\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create new variables\n",
    "tota15 = dst(totals15,11.0)\n",
    "tota14 = dst(totals14,11.0)\n",
    "tota13 = dst(totals13,11.0)\n",
    "tota12 = dst(totals12,11.0)\n",
    "tota11 = dst(totals11,12.0)\n",
    "tota10 = dst(totals10,12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>weather</th>\n",
       "      <th>crashes</th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>conv</th>\n",
       "      <th>Year_x</th>\n",
       "      <th>Tax_On_Fuel</th>\n",
       "      <th>Tax_on_License</th>\n",
       "      <th>Tot_Hwy_Exp</th>\n",
       "      <th>Year_y</th>\n",
       "      <th>Population</th>\n",
       "      <th>DST</th>\n",
       "      <th>prox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42003</td>\n",
       "      <td>Rain</td>\n",
       "      <td>2</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>1</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42003</td>\n",
       "      <td>Snow</td>\n",
       "      <td>2</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>42003</td>\n",
       "      <td>Rain</td>\n",
       "      <td>2</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>13</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>42003</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2010</td>\n",
       "      <td>15</td>\n",
       "      <td>42.003</td>\n",
       "      <td>2010</td>\n",
       "      <td>$2,020,099</td>\n",
       "      <td>$2,546,905</td>\n",
       "      <td>$6,738,126</td>\n",
       "      <td>2010</td>\n",
       "      <td>12712343</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit weather  crashes         state  year  week    conv Year_x  \\\n",
       "0   42003   Clear        0  Pennsylvania  2010     1  42.003   2010   \n",
       "1   42003    Rain        2  Pennsylvania  2010     2  42.003   2010   \n",
       "2   42003   Clear        1  Pennsylvania  2010     3  42.003   2010   \n",
       "3   42003   Clear        0  Pennsylvania  2010     4  42.003   2010   \n",
       "4   42003   Clear        0  Pennsylvania  2010     5  42.003   2010   \n",
       "5   42003   Clear        0  Pennsylvania  2010     6  42.003   2010   \n",
       "6   42003   Clear        0  Pennsylvania  2010     7  42.003   2010   \n",
       "7   42003    Snow        2  Pennsylvania  2010     8  42.003   2010   \n",
       "8   42003   Clear        2  Pennsylvania  2010     9  42.003   2010   \n",
       "9   42003   Clear        0  Pennsylvania  2010    10  42.003   2010   \n",
       "10  42003   Clear        0  Pennsylvania  2010    11  42.003   2010   \n",
       "11  42003   Clear        0  Pennsylvania  2010    12  42.003   2010   \n",
       "12  42003    Rain        2  Pennsylvania  2010    13  42.003   2010   \n",
       "13  42003   Clear        2  Pennsylvania  2010    14  42.003   2010   \n",
       "14  42003   Clear        0  Pennsylvania  2010    15  42.003   2010   \n",
       "\n",
       "   Tax_On_Fuel Tax_on_License Tot_Hwy_Exp  Year_y  Population  DST  prox  \n",
       "0   $2,020,099     $2,546,905  $6,738,126    2010    12712343    0   -11  \n",
       "1   $2,020,099     $2,546,905  $6,738,126    2010    12712343    0   -10  \n",
       "2   $2,020,099     $2,546,905  $6,738,126    2010    12712343    0    -9  \n",
       "3   $2,020,099     $2,546,905  $6,738,126    2010    12712343    0    -8  \n",
       "4   $2,020,099     $2,546,905  $6,738,126    2010    12712343    0    -7  \n",
       "5   $2,020,099     $2,546,905  $6,738,126    2010    12712343    0    -6  \n",
       "6   $2,020,099     $2,546,905  $6,738,126    2010    12712343    0    -5  \n",
       "7   $2,020,099     $2,546,905  $6,738,126    2010    12712343    0    -4  \n",
       "8   $2,020,099     $2,546,905  $6,738,126    2010    12712343    0    -3  \n",
       "9   $2,020,099     $2,546,905  $6,738,126    2010    12712343    0    -2  \n",
       "10  $2,020,099     $2,546,905  $6,738,126    2010    12712343    0    -1  \n",
       "11  $2,020,099     $2,546,905  $6,738,126    2010    12712343    1     0  \n",
       "12  $2,020,099     $2,546,905  $6,738,126    2010    12712343    0     1  \n",
       "13  $2,020,099     $2,546,905  $6,738,126    2010    12712343    0     2  \n",
       "14  $2,020,099     $2,546,905  $6,738,126    2010    12712343    0     3  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check work\n",
    "tota10.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finals = [tota15,tota14,tota13,tota12,tota11,tota10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totals = pd.concat(finals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop unnecessary duplicate variables\n",
    "totals = totals.drop(['Year_x','Year_y'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few states in my sample that do not follow DST and are therefore omitted from the study. The District of Columbia is also omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop non-DST states\n",
    "totals = totals.drop(totals[(totals['state'] == 'Arizona')].index)\n",
    "totals = totals.drop(totals[(totals['state'] == 'District of Columbia')].index)\n",
    "totals = totals.drop(totals[(totals['state'] == 'Hawaii')].index)\n",
    "\n",
    "#Drop anomaly of week 0\n",
    "totals = totals.drop(totals[(totals['week'] == 0)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>weather</th>\n",
       "      <th>crashes</th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>conv</th>\n",
       "      <th>Tax_On_Fuel</th>\n",
       "      <th>Tax_on_License</th>\n",
       "      <th>Tot_Hwy_Exp</th>\n",
       "      <th>Population</th>\n",
       "      <th>DST</th>\n",
       "      <th>prox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166309</th>\n",
       "      <td>50017</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2010</td>\n",
       "      <td>49</td>\n",
       "      <td>50.017</td>\n",
       "      <td>$99,278</td>\n",
       "      <td>$106,558</td>\n",
       "      <td>$337,990</td>\n",
       "      <td>625982</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166310</th>\n",
       "      <td>50017</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2010</td>\n",
       "      <td>50</td>\n",
       "      <td>50.017</td>\n",
       "      <td>$99,278</td>\n",
       "      <td>$106,558</td>\n",
       "      <td>$337,990</td>\n",
       "      <td>625982</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166311</th>\n",
       "      <td>50017</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2010</td>\n",
       "      <td>51</td>\n",
       "      <td>50.017</td>\n",
       "      <td>$99,278</td>\n",
       "      <td>$106,558</td>\n",
       "      <td>$337,990</td>\n",
       "      <td>625982</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166312</th>\n",
       "      <td>50017</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2010</td>\n",
       "      <td>52</td>\n",
       "      <td>50.017</td>\n",
       "      <td>$99,278</td>\n",
       "      <td>$106,558</td>\n",
       "      <td>$337,990</td>\n",
       "      <td>625982</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166313</th>\n",
       "      <td>50017</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2010</td>\n",
       "      <td>53</td>\n",
       "      <td>50.017</td>\n",
       "      <td>$99,278</td>\n",
       "      <td>$106,558</td>\n",
       "      <td>$337,990</td>\n",
       "      <td>625982</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unit weather  crashes    state  year  week    conv Tax_On_Fuel  \\\n",
       "166309  50017   Clear        0  Vermont  2010    49  50.017     $99,278   \n",
       "166310  50017   Clear        0  Vermont  2010    50  50.017     $99,278   \n",
       "166311  50017   Clear        0  Vermont  2010    51  50.017     $99,278   \n",
       "166312  50017   Clear        0  Vermont  2010    52  50.017     $99,278   \n",
       "166313  50017   Clear        0  Vermont  2010    53  50.017     $99,278   \n",
       "\n",
       "       Tax_on_License Tot_Hwy_Exp  Population  DST  prox  \n",
       "166309       $106,558    $337,990      625982    0    37  \n",
       "166310       $106,558    $337,990      625982    0    38  \n",
       "166311       $106,558    $337,990      625982    0    39  \n",
       "166312       $106,558    $337,990      625982    0    40  \n",
       "166313       $106,558    $337,990      625982    0    41  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check work\n",
    "totals.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save data\n",
    "totals.to_csv(\"/Users/tristanmoser/files/tristan/488/project/NHSA/weather/Totals2wks.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now ready for analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
